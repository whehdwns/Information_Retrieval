{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d030354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import re\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66aef02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(sys.argv[1], 'r') as f:\n",
    "#     contents = f.read()\n",
    "headline_file=open('headlines.txt',\"r\")\n",
    "headline_content = headline_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64e65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "regextoken = RegexpTokenizer(r'<P ID=\\d+>(.*?)</P>')\n",
    "headline_text_list = regextoken.tokenize(headline_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c0328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "#     lower-case words\n",
    "#     Change short term to long terms for verb.\n",
    "#     remove punctuation\n",
    "#         https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "\n",
    "def normalization(word):\n",
    "    word= word.lower()\n",
    "    word = word.replace(\"'re\",' are').replace(\"'m'\", ' am').replace(\"'s\",' is').replace(\"n't\",' not').replace(\"'ve\",' have').replace(\"'d\",' had').replace(\"'ll\",' will')\n",
    "    word = word.replace(\"'\",'')\n",
    "    word  = re.sub(r'[^\\w\\s]', '', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef63c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Terms\n",
    "# 1. Normalized the text \n",
    "# 2. It tokenized the text and count the occurence of the text\n",
    "# 3. It returns the document id and count for each of the terms.\n",
    "# 4. It also count the number of terms and documents. \n",
    "\n",
    "def calculate_terms(listed):\n",
    "    normalized_text = []\n",
    "    collection_frequency = Counter()\n",
    "    document_frequency = Counter()\n",
    "    output_wordlist_dict ={}\n",
    "    terms_frequency = defaultdict(lambda: Counter([]))\n",
    "    \n",
    "    for i in range(len(listed)):\n",
    "        normalized_text.append(normalization(listed[i]))\n",
    "    \n",
    "    for i in range(len(normalized_text)):\n",
    "        tokenized_list= []\n",
    "        for j in normalized_text[i].split():\n",
    "            tokenized_list.append(j)\n",
    "        output_wordlist_dict[i] = Counter(tokenized_list)\n",
    "        collection_frequency.update(tokenized_list)\n",
    "        document_frequency.update(set(tokenized_list))\n",
    "        \n",
    "    for key, value in output_wordlist_dict.items():\n",
    "        for term, term_cnt in value.items():\n",
    "            terms_frequency[term][key] += term_cnt\n",
    "    \n",
    "    return normalized_text, collection_frequency, document_frequency, terms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b414702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary List\n",
    "# 1. It stores information about a term (Document Frequency and offset)\n",
    "# 2. The dictionary is sorted by term. \n",
    "# 3. It starts from 0 and counts the number document frequency and term count. \n",
    "\n",
    "def dictionary_list(listed):\n",
    "    sort_dict = {}\n",
    "    result_sort_dict = {}\n",
    "    offset_sum = 0\n",
    "    offset_i = 0\n",
    "    sort_dict = OrderedDict(sorted(listed.items()))\n",
    "    for i, value in enumerate(sort_dict.keys()):\n",
    "        offset_i = len(sort_dict[value]) * 2 \n",
    "        result_sort_dict[value] = len(sort_dict[value].values()),offset_sum\n",
    "        offset_sum = offset_sum + offset_i \n",
    "    return result_sort_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52cf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted file\n",
    "# 1. It stores the sorted entries as an inverted file\n",
    "\n",
    "def inverted_file(key, dict_listed):\n",
    "    inverted_list = []\n",
    "    for i in key:\n",
    "        for docid, term_cnt in dict_listed[i].items():\n",
    "            inverted_list.append(docid)\n",
    "            inverted_list.append(term_cnt)\n",
    "    return inverted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a99fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store_Inverted_bin\n",
    "# 1. It stores the inverted file as binary file. \n",
    "# 2. It stored this binary file as 4-byte integers. \n",
    "\n",
    "def Store_Inverted_bin(file):\n",
    "    with open(\"inverted_fiile_binary.bin\", \"wb\") as fb:\n",
    "        for num in file:\n",
    "            fb.write(num.to_bytes(4, \"big\"))\n",
    "    print(\"Inverted File is created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ac37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text, collection_freq, document_freq, posting_list_output = calculate_terms(headline_text_list)\n",
    "\n",
    "postings_list_terms =['heidelberg', 'cesium', 'trondheim', 'crustacean']\n",
    "\n",
    "for i in postings_list_terms:\n",
    "    posting_list_output[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eddefed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted File is created.\n"
     ]
    }
   ],
   "source": [
    "dict_pos_output = dictionary_list(posting_list_output)\n",
    "byte_file = inverted_file(dict_pos_output.keys(), posting_list_output)\n",
    "Store_Inverted_bin(byte_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46495af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraph: 500000\n",
      "Number of unique words observed: 174195\n",
      "The total number of words encountered: 4586860\n"
     ]
    }
   ],
   "source": [
    "print('Number of paragraph:', len(normalized_text))\n",
    "print('Number of unique words observed:', len(document_freq))\n",
    "print('The total number of words encountered:', sum(collection_freq.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc039919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original_text: 39381610 bytes\n",
      "Size of Inverted File: 35970152 bytes\n",
      "Size of Dictionary: 5242968 bytes\n"
     ]
    }
   ],
   "source": [
    "print('Size of original_text: ' + str(os.path.getsize('headlines.txt')) + ' bytes')\n",
    "print('Size of Inverted File: ' + str(os.path.getsize('inverted_fiile_binary.bin')) + ' bytes')\n",
    "print('Size of Dictionary: ' + str(sys.getsizeof(dict_pos_output)) + ' bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a51222c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Frequency\n",
    "# 1. It prints the  document frequency and postings list for terms.\n",
    "# 2. It prints the index of posting list for terms.\n",
    "# 3. It reads inverted_file binary file every 4 byte, then gets the posting list for the terms. \n",
    "\n",
    "def document_freqency(dictionary_output,binary_file, terms):\n",
    "    term = terms.lower()\n",
    "    print(\"document frequency for \"+terms+\" : \",dictionary_output[terms][0])\n",
    "    if (dictionary_output[terms][0] == 0):\n",
    "        print(\"The \"+ terms + \" does not exit in the document.\")\n",
    "    terms_position = dictionary_output[term][1]\n",
    "    range_of_terms_in_positing_list = list(dictionary_output.keys()).index(term)\n",
    "    if len(list(dictionary_output)) != range_of_terms_in_positing_list+1:\n",
    "        next_term = list(dictionary_output.keys())[range_of_terms_in_positing_list+1]\n",
    "    else:\n",
    "        print(\"The terms \"+ terms+\" is in end of the word. There is no next word\")\n",
    "        return\n",
    "    next_term_position = dictionary_output[next_term][1]\n",
    "    range_index = [terms_position, next_term_position]\n",
    "    print(\"index of range for \"+terms+\" : \", range_index)\n",
    "    list_num = []\n",
    "    with open(binary_file, \"br\") as bf:\n",
    "        for _ in range(terms_position):\n",
    "            data = bf.read(4)\n",
    "        for _ in range(terms_position, next_term_position):\n",
    "            data = bf.read(4)\n",
    "            number = int.from_bytes(data,\"big\")\n",
    "            list_num.append(number)\n",
    "    print(\"posting list for \"+terms+\" : \")\n",
    "    print(list_num)\n",
    "    return list_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47c26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faca8776",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document frequency for heidelberg :  8\n",
      "index of range for heidelberg :  [3588994, 3589010]\n",
      "posting list for heidelberg : \n",
      "[114329, 1, 135133, 1, 174780, 1, 221099, 1, 243837, 1, 452545, 1, 491139, 1, 491278, 1]\n",
      "-----------------\n",
      "document frequency for cesium :  4\n",
      "index of range for cesium :  [1671216, 1671224]\n",
      "posting list for cesium : \n",
      "[50019, 1, 280669, 1, 348143, 1, 391938, 1]\n",
      "-----------------\n",
      "document frequency for trondheim :  0\n",
      "The trondheim does not exit in the document.\n",
      "index of range for trondheim :  [8232872, 8232872]\n",
      "posting list for trondheim : \n",
      "[]\n",
      "-----------------\n",
      "document frequency for crustacean :  2\n",
      "index of range for crustacean :  [2109786, 2109790]\n",
      "posting list for crustacean : \n",
      "[230747, 1, 234923, 1]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "postings_list_terms = ['Heidelberg', 'cesium', 'Trondheim', 'crustacean']\n",
    "\n",
    "for i in postings_list_terms:\n",
    "    terms = i.lower()\n",
    "    document_freqency(dict_pos_output, \"inverted_fiile_binary.bin\", terms)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce4ccfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Frequency for Hopkins is (71, 3714138)\n",
      "Document Frequency for Stanford is (150, 7287324)\n",
      "Document Frequency for Brown is (769, 1410140)\n",
      "Document Frequency for college is (1909, 1866432)\n"
     ]
    }
   ],
   "source": [
    "word_list = ['Hopkins', 'Stanford', 'Brown', 'college']\n",
    "\n",
    "for i in word_list:\n",
    "    print('Document Frequency for '+i+' is '+ str(dict_pos_output[i.lower()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10286fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document frequency for elon :  60\n",
      "index of range for elon :  [2560860, 2560980]\n",
      "posting list for elon : \n",
      "[3393, 1, 16330, 1, 19262, 1, 21341, 1, 29749, 1, 39287, 1, 44321, 1, 45978, 1, 52990, 1, 57023, 1, 57787, 1, 71988, 1, 84806, 1, 87959, 1, 98830, 1, 103398, 1, 104204, 1, 115207, 1, 122603, 1, 127050, 1, 128662, 1, 131441, 1, 131448, 1, 131514, 1, 135942, 1, 146965, 1, 151171, 1, 159147, 1, 186107, 1, 194998, 1, 197341, 1, 239304, 1, 240040, 1, 245923, 1, 249585, 1, 251252, 1, 274393, 1, 277539, 1, 283098, 1, 297139, 1, 301627, 1, 303775, 1, 305183, 1, 306988, 1, 307162, 1, 341755, 1, 342182, 1, 354346, 1, 369772, 1, 383528, 1, 399001, 1, 399946, 1, 420082, 1, 431495, 1, 431739, 1, 449684, 1, 456443, 1, 461816, 1, 479190, 1, 482769, 1]\n",
      "document frequency for musk :  53\n",
      "index of range for musk :  [5189044, 5189150]\n",
      "posting list for musk : \n",
      "[3393, 1, 16330, 1, 19262, 1, 21341, 1, 29749, 1, 44321, 1, 45978, 1, 52990, 1, 57023, 1, 57787, 1, 84806, 1, 98830, 1, 115207, 1, 122603, 1, 127050, 1, 128662, 1, 131448, 1, 131514, 1, 146965, 1, 159147, 1, 186107, 1, 194998, 1, 197341, 1, 229771, 1, 239304, 1, 240040, 1, 245923, 1, 249585, 1, 252219, 1, 253923, 1, 260295, 1, 267866, 1, 274393, 1, 283098, 1, 297139, 1, 303775, 1, 305183, 1, 306988, 1, 341755, 1, 342182, 1, 354346, 1, 369772, 1, 383528, 1, 399001, 1, 399946, 1, 420082, 1, 431495, 1, 431739, 1, 437850, 1, 449684, 1, 455802, 1, 456443, 1, 482769, 1]\n"
     ]
    }
   ],
   "source": [
    "elon_list = document_freqency(dict_pos_output, \"inverted_fiile_binary.bin\", 'Elon'.lower())\n",
    "musk_list = document_freqency(dict_pos_output, \"inverted_fiile_binary.bin\", 'Musk'.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "583fb8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection of postings list for each term: Elon and Musk: 46\n",
      "[3393, 16330, 19262, 21341, 29749, 44321, 45978, 52990, 57023, 57787, 84806, 98830, 115207, 122603, 127050, 128662, 131448, 131514, 146965, 159147, 186107, 194998, 197341, 239304, 240040, 245923, 249585, 274393, 283098, 297139, 303775, 305183, 306988, 341755, 342182, 354346, 369772, 383528, 399001, 399946, 420082, 431495, 431739, 449684, 456443, 482769]\n"
     ]
    }
   ],
   "source": [
    "set_elon =set(elon_list)\n",
    "set_musk = set(musk_list)\n",
    "\n",
    "setone = {1}\n",
    "set_same = set_elon.intersection(set_musk) - setone\n",
    "print('Intersection of postings list for each term: Elon and Musk: '+ str(len(list(set_same))))\n",
    "print(sorted(set_same))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
