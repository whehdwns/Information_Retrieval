{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d030354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import time\n",
    "import operator\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f769fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66aef02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cord19_file=open('data/cord19/cord19.txt',\"r\", encoding=\"UTF-8\")\n",
    "cord19_content = cord19_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474d1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cord19_key_file =open('data/cord19.topics.keyword.txt',\"r\")\n",
    "cord19_key_content = cord19_key_file.read()\n",
    "\n",
    "cord19_qs_file =open('data/cord19.topics.question.txt',\"r\")\n",
    "cord19_qs_content = cord19_qs_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64e65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "regextoken_P = RegexpTokenizer(r'<P ID=\\d+>(.*?)</P>')\n",
    "regextoken_Q = RegexpTokenizer(r'<Q ID=\\d+>(.*?)</Q>')\n",
    "\n",
    "cord19_text_list = regextoken_P.tokenize(cord19_content)\n",
    "cord19_key_text_list = regextoken_Q.tokenize(cord19_key_content)\n",
    "cord19_qs_text_list = regextoken_Q.tokenize(cord19_qs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c0328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "#     lower-case words\n",
    "#     Change short term to long terms for verb.\n",
    "#     remove punctuation\n",
    "#         https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "#     remove numbers\n",
    "\n",
    "def normalization(word):\n",
    "    word= word.lower()\n",
    "    word = word.replace(\"'re\",' are').replace(\"'m'\", ' am').replace(\"'s\",' is').replace(\"n't\",' not').replace(\"'ve\",' have').replace(\"'d\",' had').replace(\"'ll\",' will')\n",
    "    word = word.replace(\"'\",'')\n",
    "    word  = re.sub(r'[^\\w\\s]', '', word)\n",
    "    word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "    word = re.sub('[0-9]', '', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef63c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Terms\n",
    "# 1. Normalized the text \n",
    "# 2. It tokenized the text and count the occurence of the text\n",
    "# 3. It returns the document id and count for each of the terms.\n",
    "# 4. It also count the number of terms and documents. \n",
    "\n",
    "def calculate_terms(listed):\n",
    "    normalized_text = []\n",
    "    collection_frequency = Counter()\n",
    "    document_frequency = Counter()\n",
    "    output_wordlist_dict ={}\n",
    "    terms_frequency = defaultdict(lambda: Counter([]))\n",
    "    \n",
    "    for i in range(len(listed)):\n",
    "        normalized_text.append(normalization(listed[i]))\n",
    "    \n",
    "    for i in range(len(normalized_text)):\n",
    "        tokenized_list= []\n",
    "        for j in normalized_text[i].split():\n",
    "            tokenized_list.append(j)\n",
    "        output_wordlist_dict[i] = Counter(tokenized_list)\n",
    "        collection_frequency.update(tokenized_list)\n",
    "        document_frequency.update(set(tokenized_list))\n",
    "        \n",
    "    for key, value in output_wordlist_dict.items():\n",
    "        for term, term_cnt in value.items():\n",
    "            terms_frequency[term][key] += term_cnt\n",
    "    \n",
    "    return normalized_text, collection_frequency, document_frequency, output_wordlist_dict, terms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b414702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary List\n",
    "# 1. It stores information about a term (Document Frequency and offset)\n",
    "# 2. The dictionary is sorted by term. \n",
    "# 3. It starts from 0 and counts the number document frequency and term count. \n",
    "\n",
    "def dictionary_list(listed):\n",
    "    sort_dict = {}\n",
    "    result_sort_dict = {}\n",
    "    offset_sum = 0\n",
    "    offset_i = 0\n",
    "    sort_dict = OrderedDict(sorted(listed.items()))\n",
    "    for i, value in enumerate(sort_dict.keys()):\n",
    "        offset_i = len(sort_dict[value]) * 2 \n",
    "        result_sort_dict[value] = len(sort_dict[value].values()),offset_sum\n",
    "        offset_sum = offset_sum + offset_i \n",
    "    return result_sort_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d52cf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted file\n",
    "# 1. It stores the sorted entries as an inverted file\n",
    "\n",
    "def inverted_file(key, dict_listed):\n",
    "    inverted_list = []\n",
    "    for i in key:\n",
    "        for docid, term_cnt in dict_listed[i].items():\n",
    "            inverted_list.append(docid)\n",
    "            inverted_list.append(term_cnt)\n",
    "    return inverted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a99fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store_Inverted_bin\n",
    "# 1. It stores the inverted file as binary file. \n",
    "# 2. It stored this binary file as 4-byte integers. \n",
    "\n",
    "def Store_Inverted_bin(file, name):\n",
    "    with open(\"Inverted_File/inverted_file_\"+name+\"_binary.bin\", \"wb\") as fb:\n",
    "        for num in file:\n",
    "            fb.write(num.to_bytes(4, \"big\"))\n",
    "    print(\"Inverted File \" + name +\" is created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bbfd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IDF\n",
    "# 1. It gest posting list and length of the document\n",
    "# 2. In posting list, it contains (frequency of the terms, offset of the terms)\n",
    "# 3. To calculate the IDF, log2(Number of document / document frequency) \n",
    "def idf_corpus(dict_corpus,N_corpus):\n",
    "    idf_dict = {}\n",
    "    for key_i in dict_corpus.keys():\n",
    "        tf_i = dict_corpus.get(key_i)[0]\n",
    "        idf_i = math.log2(N_corpus/tf_i)\n",
    "        idf_dict[key_i] = idf_i\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38b697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DFx IDF\n",
    "# It gets term frequency for each documents.\n",
    "# 1. It iterates through documents.\n",
    "# 2. It iterates through terms in document.\n",
    "# 3. If the term in document does not exit in IDF, it sets to 0.\n",
    "# 4. Else it multiplies term freqeuncy by IDF.\n",
    "\n",
    "def tf_idf(post_list,idf_matrix):\n",
    "    weight_matrix =[]\n",
    "    for i, j in post_list.items():\n",
    "        idf ={}\n",
    "        for k in j:\n",
    "            if k not in idf_matrix:\n",
    "                idf_matrix[k] = 0\n",
    "            else:\n",
    "                idf[k] = idf_matrix[k]*j[k]\n",
    "        weight_matrix.append(idf)                       \n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568972f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_length(weight):\n",
    "    length_matrix = {}\n",
    "    for doc_i in range(len(weight)):\n",
    "        length_matrx = []\n",
    "        for i in weight[doc_i].values():\n",
    "            length_matrx.append(i)\n",
    "        sum_of_squares = sum(map(lambda k : k * k, length_matrx))\n",
    "        vlength = math.sqrt(sum_of_squares)\n",
    "        length_matrix[doc_i] = vlength\n",
    "    return length_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ba4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarities(doc_weight, query_weight, doc_length, query_length, query_term_freq):\n",
    "    N = len(doc_weight)\n",
    "    cos_score = []\n",
    "    for i in range(len(query_term_freq)):\n",
    "        cos_score.append([0]*N)\n",
    "        for j  in query_term_freq[i].keys():\n",
    "            query_tfidf = 0\n",
    "            if query_weight[i].get(j):\n",
    "                query_tfidf = query_weight[i].get(j)\n",
    "            for k in range(len(doc_weight)):\n",
    "                if(query_length[i] != 0) & (doc_length[k] != 0):\n",
    "                    if(doc_weight[k].get(j)):\n",
    "                        #Document Length * Query Length\n",
    "                        doc_query_length = doc_length[k] * query_length[i]\n",
    "                        # tf-idf weight of term in document * tf-idf weight of term in query\n",
    "                        doc_query_vector = doc_weight[k].get(j) * query_tfidf\n",
    "                        cos_score[i][k] += doc_query_vector / doc_query_length  \n",
    "    return cos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622d9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ranking(doc_weight, cos_score, jhuid, filename):\n",
    "    print(\"Creating Score Ranking\")\n",
    "    N = len(doc_weight)\n",
    "    score_results = []\n",
    "    for score in cos_score:\n",
    "        result =[]\n",
    "        for i in range(N):\n",
    "            result.append((score[i], i))\n",
    "        result.sort(reverse= True)\n",
    "        score_results.append(result)\n",
    "    score_output = open(filename, \"w\")\n",
    "    for query_id in range(len(score_results)):\n",
    "        for j in range(100):\n",
    "            doc_id, cos_score = score_results[query_id][j]\n",
    "            score_output.write(str(query_id+1) + \" Q0 \" + str(cos_score) + \" \" +  str(j+1) + \" \" + str(doc_id) + \" \" + jhuid + '\\n')\n",
    "    score_output.close()\n",
    "    print(\"Score Ranking file (\" + filename+ \" ) is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e9c4323",
   "metadata": {},
   "outputs": [],
   "source": [
    "cord19_normalized_text, cord19_collection_freq, cord19_document_freq, cord19_term_freq, cord19_posting_list_output = calculate_terms(cord19_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c2272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cord19\n",
      "Number of paragraph: 191175\n",
      "Number of unique words observed: 450118\n",
      "The total number of words encountered: 50097612\n"
     ]
    }
   ],
   "source": [
    "print(\"Cord19\")\n",
    "print('Number of paragraph:', len(cord19_normalized_text))\n",
    "print('Number of unique words observed:', len(cord19_document_freq))\n",
    "print('The total number of words encountered:', sum(cord19_collection_freq.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f522485",
   "metadata": {},
   "outputs": [],
   "source": [
    "cord19_key_normalized_text, cord19_key_collection_freq, cord19_key_document_freq, cord19_key_term_freq, cord19_key_posting_list_output = calculate_terms(cord19_key_text_list)\n",
    "cord19_qs_normalized_text, cord19_qs_collection_freq, cord19_qs_document_freq, cord19_qs_term_freq, cord19_qs_posting_list_output = calculate_terms(cord19_qs_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbc7c2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cord19 Keyword\n",
      "Number of paragraph: 50\n",
      "Number of unique words observed: 101\n",
      "The total number of words encountered: 162\n",
      "Cord19 Question\n",
      "Number of paragraph: 50\n",
      "Number of unique words observed: 233\n",
      "The total number of words encountered: 530\n"
     ]
    }
   ],
   "source": [
    "# Cord19 Keyword\n",
    "print(\"Cord19 Keyword\")\n",
    "print('Number of paragraph:', len(cord19_key_normalized_text))\n",
    "print('Number of unique words observed:', len(cord19_key_document_freq))\n",
    "print('The total number of words encountered:', sum(cord19_key_collection_freq.values()))\n",
    "\n",
    "print(\"Cord19 Question\")\n",
    "print('Number of paragraph:', len(cord19_qs_normalized_text))\n",
    "print('Number of unique words observed:', len(cord19_qs_document_freq))\n",
    "print('The total number of words encountered:', sum(cord19_qs_collection_freq.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eddefed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted File cord19 is created.\n",
      "CPU times: total: 33.5 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cord19_dict_pos_output = dictionary_list(cord19_posting_list_output)\n",
    "cord19_byte_file = inverted_file(cord19_dict_pos_output.keys(), cord19_posting_list_output)\n",
    "Store_Inverted_bin(cord19_byte_file, \"cord19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc039919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original_text: 359302564 bytes\n",
      "Size of Cord19 Inverted File: 190324096 bytes\n",
      "Size of Dictionary: 20971608 bytes\n"
     ]
    }
   ],
   "source": [
    "print('Size of original_text: ' + str(os.path.getsize('data/cord19/cord19.txt')) + ' bytes')\n",
    "print('Size of Cord19 Inverted File: ' + str(os.path.getsize('Inverted_File/inverted_fiile_cord19_binary.bin')) + ' bytes')\n",
    "print('Size of Dictionary: ' + str(sys.getsizeof(cord19_dict_pos_output)) + ' bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "617a5d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing IDF, TF-IDF, Vector Length for Cord19 Document\n",
      "The time of execution of Cord19(IDF, TF-IDF, Vector Length) is : 51.611387491226196 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing IDF, TF-IDF, Vector Length for Cord19 Document\")\n",
    "cord19_pre_start = time.time()\n",
    "idf_matrix = idf_corpus(cord19_dict_pos_output,len(cord19_normalized_text))\n",
    "cord19_weight = tf_idf(cord19_term_freq, idf_matrix)\n",
    "cord19_length = vector_length(cord19_weight)\n",
    "cord19_pre_end = time.time()\n",
    "print(\"The time of execution of Cord19(IDF, TF-IDF, Vector Length) is :\",(cord19_pre_end-cord19_pre_start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f44ec6",
   "metadata": {},
   "source": [
    "## Cord19 Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3516fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cord19_key_dict_pos_output = dictionary_list(cord19_key_posting_list_output)\n",
    "# cord19_key_byte_file = inverted_file(cord19_key_dict_pos_output.keys(), cord19_key_posting_list_output)\n",
    "# Store_Inverted_bin(cord19_key_byte_file, \"cord19_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bfec09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing IDF, TF-IDF, Vector Length for Cord19 Keyword Query\n",
      "The time of execution Cord19 Keyword(IDF, TF-IDF, Vector Length) is : 0.003785848617553711 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing IDF, TF-IDF, Vector Length for Cord19 Keyword Query\")\n",
    "\n",
    "cord19_key_pre_start = time.time()\n",
    "#cord19_key_idf_matrix = idf_corpus(cord19_key_dict_pos_output,len(cord19_key_normalized_text))\n",
    "cord19_key_weight = tf_idf(cord19_key_term_freq, idf_matrix)\n",
    "cord19_key_length = vector_length(cord19_key_weight)\n",
    "cord19_key_pre_end = time.time()\n",
    "print(\"The time of execution Cord19 Keyword(IDF, TF-IDF, Vector Length) is :\",(cord19_key_pre_end-cord19_key_pre_start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b850bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cord19_key_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78bac41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coronavirus': 2.026618955602212, 'origin': 5.533656625511048}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cord19_key_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ba6a18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.893092570142482"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cord19_key_length[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29538eb2",
   "metadata": {},
   "source": [
    "## Cord19 Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79be182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cord19_qs_dict_pos_output = dictionary_list(cord19_qs_posting_list_output)\n",
    "# cord19_qs_byte_file = inverted_file(cord19_qs_dict_pos_output.keys(), cord19_qs_posting_list_output)\n",
    "# Store_Inverted_bin(cord19_qs_byte_file, \"cord19_qs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84d247cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing IDF, TF-IDF, Vector Length for Cord19 Question Query\n",
      "The time of execution of Cord19 Question (IDF, TF-IDF, Vector Length) is : 0.004987001419067383 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing IDF, TF-IDF, Vector Length for Cord19 Question Query\")\n",
    "cord19_qs_pre_start = time.time()\n",
    "# cord19_qs_idf_matrix = idf_corpus(cord19_qs_dict_pos_output,len(cord19_qs_normalized_text))\n",
    "cord19_qs_weight = tf_idf(cord19_qs_term_freq, idf_matrix)\n",
    "cord19_qs_length = vector_length(cord19_qs_weight)\n",
    "cord19_qs_pre_end = time.time()\n",
    "print(\"The time of execution of Cord19 Question (IDF, TF-IDF, Vector Length) is :\",(cord19_qs_pre_end-cord19_qs_pre_start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e59d89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'what': 4.531386177063322,\n",
       " 'is': 0.7887470080604575,\n",
       " 'the': 0.29054840512573527,\n",
       " 'origin': 5.533656625511048,\n",
       " 'of': 0.3000032691840576,\n",
       " 'covid': 1.3763323422808138}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cord19_qs_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a8d229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3379594732539655"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cord19_qs_length[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e2e868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Score for Keyword\n",
      "Creating Score Ranking\n",
      "Score Ranking file (testing2/dcho13-a.txt ) is created\n",
      "The time of execution of Cord19 Keyword Cosine Score and Ranking is : 33.861650228500366 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Score for Keyword\")\n",
    "cord19_key_start = time.time()\n",
    "cos_score_keyword = cosine_similarities(cord19_weight, cord19_key_weight, cord19_length, cord19_key_length, cord19_key_term_freq)\n",
    "score_ranking(cord19_weight, cos_score_keyword, 'dcho13','testing2/dcho13-a.txt' )\n",
    "cord19_key_end = time.time()\n",
    "print(\"The time of execution of Cord19 Keyword Cosine Score and Ranking is :\",(cord19_key_end-cord19_key_start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc464d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Score for Question\n",
      "Creating Score Ranking\n",
      "Score Ranking file (testing2/dcho13-b.txt ) is created\n",
      "The time of execution of Cord19 Question Cosine Score and Ranking is : 93.19122266769409 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Score for Question\")\n",
    "cord19_qs_start = time.time()\n",
    "cos_score_question = cosine_similarities(cord19_weight, cord19_qs_weight, cord19_length, cord19_qs_length, cord19_qs_term_freq)\n",
    "score_ranking(cord19_weight, cos_score_question, 'dcho13','testing2/dcho13-b.txt' )\n",
    "cord19_qs_end = time.time()\n",
    "print(\"The time of execution of Cord19 Question Cosine Score and Ranking is :\",(cord19_qs_end-cord19_qs_start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28c963dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 319.1791760921478 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Total execution time: %s seconds\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
